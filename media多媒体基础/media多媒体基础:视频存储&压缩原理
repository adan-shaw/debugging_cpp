1.计算机视频数据存储原理:

	计算机是如何存储视频数据的?
		* 视频描述, 声明info[不重要, 仅供视频解析器阅读, 方便让视频解析器准备好解析算法]
		* 时间轴数据
		* 图片(视频轨道)
		* 音频轨道
		* 字幕轨道(如果有)


	* 时间轴数据:
		一般不存在的, 如果存在时间轴数据, 则一般比较冗余:
			每张图片, 需要加时间轴坐标;
			每节音频, 需要加时间轴坐标;
			每节字幕, 需要加时间轴坐标;
		默认的时间轴, 就是从0->结束, 单向的, 视频轨道, 音频轨道, 字幕轨道, 直行;
		因此, 时间轴数据一般是不存在的;

		编辑器一般也是自己根据帧率, 来充当时间轴的, 23帧等于每秒播放23张照片, 这23张照片的时间间隔, 都是一样的,
		因此, 帧率实际上充当着: 准时间轴的角色, 方便视频轨道, 音频轨道, 字幕轨道对齐;
		因此, 解码播放器想要播放视频, 必须要知道的两个要素是:
			* 每张照片的统一像素网格是480*640, 还是1024*768, 还是...
			* 帧率


	* 图片(视频轨道):
		视频文件, 实际上是一张张照片组成的, 只不过每秒播放15-30 张照片, 我们普通人感觉不出来而已,
		一般最高的帧率, 也就30 帧, 哪怕是打游戏, 频繁变动模型的情况下, 30 帧也足够了, 看电影一般只需要15 帧;

		视频文件中, 每张照片的像素网格, 都是统一的, 这是必须条件!!
		如果出现那张照片损坏了, 就会有雪花, 以前看CD 光盘电影, 有雪花就是这个原因;


	* 音频轨道:
		根据帧率, 根据播放时常, 直接代入到视频中;
		由于音频数据是波形数据, 非常不好压缩!!(真不知道那些做音频数据压缩, 处理算法, 是怎样做的)
		又由于音频数据, 数据量不大, 一般压缩视频, 也不会对音频轨道进行处理的;

		因此, 音频数据, 基本上就是直接对齐时间轴, 就完事了;


	* 字幕轨道(如果有):
		remb, mkv 等高端视频封装格式, 是有字幕轨道的, 是可以手动编辑, 多次编辑, 调整字幕轨道的;
		mp4, m4v 等低端视频封装格式, 是没有字幕轨道的, 字幕数据直接烧写进视频里面, 省事, 也简单节约;

		字幕数据, 基本上也是直接对齐时间轴, 就完事了;





2.视频数据压缩原理:
	视频数据压缩, 一般不会压缩音频和字幕, 因为想对于视频数据, 这些都是小毛见大毛, 所以基本上不用压缩;
	因此, 视频数据压缩的重点, 主要是压缩视频轨道, 常见的重要压缩要点是:
		* 帧率(减少每秒播放的照片数据, 可以非常客观地削减视频数据的大小)
		* 调整每张照片的像素网格:
			其实这部分, 已经是视频剪裁的范畴了, 只不过剪裁视频时, 你是否会保留原本的像素比例, 还是重新定义一个新的像素比例, 例如:
				1024*768 转480*640, 视频比例同样是3:4, 会压缩掉很多数据, 但视频画面不会有损失;
				1024*768 转480*480, 视频比例从3:4, 转换为1:1, 会压缩掉很多数据, 同时视频画面会有损失;
				1024*768 转1024*768, 基本上没有任何操作, ffmpeg 会操作得非常快, kdenlive 编辑器会操作得非常快, 
														 这种对齐操作, 常见在视频剪辑中, 
														 只要对齐了视频像素网格, 最终导出视频文件时, 速度会非常快, 因为底层ffmpeg 工作效率高了, 所以转码快了;
														 (ps: 大部分视频编辑软件, 最终还是用ffmpeg 进行操作的, 别忘了, 所以ffmpeg 效率高了, 一切都快了)





3.摄像头拍摄出来的视频文件 && smart camera 技术:
	一般非最小化压缩的视频文件, 可能都会存在时间轴坐标数据(应该不存在的, 不用幻想, 不再讨论);

	因此, 视频压缩的本质可能是:
		如果视频中, 每张照片都附带了'像素点坐标pos', 则把它删除, 转换为jpg 照片存放, 这样的确可以压缩大量的空间;
		但一般:
			手机相机拍摄, 例如最高是4000万像素, 那么拍摄视频也只会是1080p 的视频, 视频数据这么烂, 足以证明: 
				视频里面的照片, 一般就已经是jpg 了, 压缩'像素点坐标pos'这种情况是很少的, 基本不存在;

		因此, 压缩视频, 基本上都是压缩帧率;
		调整视频像素网格, 都属于剪裁视频的范畴了;


	smart camera 技术:
		在监控摄像头中, 常用到smart camera 技术, 由于监控摄像头, 长期会碰到:
			* 长时间, 画面不动的情况
		如果这时候帧率还是一样, 就会消耗大量的存储空间;

		聪明的工程师, 也想到了首帧不变的情况下, 下一帧直接跑空时间轴, 不存任何数据, 只记录时间轴在跑, 
		这样就可以节省大量静止画面的数据!!

		一般使用smart camera 技术的监控摄像头, 
		如果一天里面没有什么东西进入画面的话, 拍摄一天24 小时, 视频文件才200MB(200万像素的摄像头, 貌似), 
		非常不可思议, 换成普通摄像头, 估计要几十GB数据;
		而且还能保持非常高清的画面, awesome !!

	smart camera 技术的难点:
		如何动态判断画面不动, 不要一点风吹草动, 就拍摄进去, 防止视频文件过大;
		又不能丢失关键的, 重要的画面, 哪怕是一点点, 这就有点犯难了;

		smart camera 算法优化, 应该是监控行业, 非常常见的, 但目前应该也有成熟的方案了;
		监控行业, 更需要的技术是:
			监控画面高清还原算法, 以提取关键画面的信息;

		当然smart camera 算法的继续优化, 也很重要啦, 但突破性较难;
		目前的smart camera 算法应该也很厉害了;





4.互联网流媒体技术原理:
	互联网流媒体技术, 重点是在压缩, 还原, 同步的基础上, 做很多工作;
	首先, 你会发现:
		互联网上面下载的视频, 基本上已经被压缩得骨头都不剩了,
		所以基本上, 这已经是最高效率的mp4 文件了, 不用怀疑;

	那么互联网流媒体技术的重点是什么?
		* 视频轴同步
		* 数据切片, 切片有序还原的技术
		* 网络稳定的维持, 断续重发技术
		* 如果有realtime 实时通话sip, 这个技术要点, 更苛刻一点;
		...

	anyway, 互联网流媒体技术中, 常见的技术要点, 就这些;
	anyway, 互联网流媒体技术中, 常见的属于有:
		推流: 推送视频流数据(附带视频时间轴还原, 通信服务质量(QoS)保障协议)
		拉流: 拉取视频流数据(附带视频时间轴还原, 通信服务质量(QoS)保障协议)
		sip: 实时会话控制协议(类似http 协议)

		转码: 视频封装格式转换(对'旧编码格式'进行解码, 编码出'新编码格式')
		编码: 生成'新编码格式'的视频
		解码: 对'编码格式'进行解码(播放需要GUI 配合才能播放视频)
		播放: 对'编码格式'进行解码+GUI配合, 将解码后的数据, 通过GUI 接口, 打到屏幕上面;

		通信服务质量(QoS)保障协议:
			RTP/RTCP
			SRTP/SRTCP
			RTMP/RTMPE
			RTMPT/RTMPS
			RTSP
			HLS

