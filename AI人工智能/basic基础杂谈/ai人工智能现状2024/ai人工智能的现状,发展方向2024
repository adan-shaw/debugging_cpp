人工智能的现状: 目前的人工智能, 还不会真正意义上的思考; 但目前的人工智能, 已经比过去的好了很多了:
	过去:
		+ 行为策略(决策-选择):       [固定决策-选择, 选择少]
		+ 算法层归纳(决策-方法):     [固定决策-方法, 方法少]
		+ 参考数据源, 成功案例(记忆): [固定记忆, 量少]
		+ 模糊思考(随机):           [固定记忆, 量少](随记忆的存储量变化而变化, 记忆存储量越多, 模糊思考能力越强)
		+ 数据标定, 校正(反馈):      [固定参数, 量少]
		+ 多维度判别感知:            [固定, 少]
				视觉: 机器人-视觉计算
				听觉: 机器人-音频识别
				触觉: 机器人-雷达测距/压力感应器/湿度感应器/温度感应器 ...
				文本检索识别: 互联网AI-最低粒度
				图片检索识别: 互联网AI-图片
				音频检索识别: 互联网AI-音频
				视频检索识别: 互联网AI-视频(目前数据压力太大, 只能重点抽查, 不能全部监控)
		+ ...
	现在:
		+ 行为策略(决策-选择):       [可新增决策-选择, 选择多]
		+ 算法层归纳(决策-方法):     [固定决策-方法, 方法一般多, 只是时代进步了, 机器并不能自己推导自然规律公式, 需要人为输入]
		+ 参考数据源, 成功案例(记忆): [可新增记忆, 量大]
		+ 模糊思考(随机):           [可新增记忆, 量大](随记忆的存储量变化而变化, 记忆存储量越多, 模糊思考能力越强)
		+ 数据标定, 校正(反馈):      [可新增参数, 量大](ps: 机器学习框架, 大模型, chatgpt 4.0 有2200亿个权值参数, 并能通过训练, 自动校正, 非人工一个一个去改)
		+ 多维度判别感知:            [固定, 多, 只是时代进步了而已]
				视觉: 机器人-视觉计算
				听觉: 机器人-音频识别
				触觉: 机器人-雷达测距/压力感应器/湿度感应器/温度感应器 ...
				文本检索识别: 互联网AI-最低粒度
				图片检索识别: 互联网AI-图片
				音频检索识别: 互联网AI-音频
				视频检索识别: 互联网AI-视频(目前数据压力太大, 只能重点抽查, 不能全部监控)
		+ ...

	这些技术的突破, 导致人工智能技术有了突破性的发展;



人工智能的未来:
	当一个又一个准确率高的AI 模型, 成功训练完毕, 渐渐会出现一个全知全能机器人;
	但这个庞大的怪兽, 就跟互联网微服务平台一样, 一个问题一个server, 渐渐组建出一个云;
	后续有更好的方法, 去更新过去的人工智能框架时, 将会是很复杂, 会陷入: 
		不断创新, 
		不断更新, 
		不断回头, 回顾更新, 纠缠不清的局面;
	但整体的发展, 会渐渐趋向于稳定, 一旦出现一套可靠的方法论, 这套方法论更新到机器学习框架, 就需要触发机器学习框架: 重新训练, 重新生成标定数据, 循环往复;



人工智能行业的方向:
	* 人工智能'零配件供应商':
		+ 前端数据采集分析器:    多维度判别感知的每个部分, 都是AI 前端数据采集器)
		+ 执行部件:            机器臂/电机制动/开关/水闸... 等等(都是传统工具, 但需要带通信网络芯片, 嵌入式芯片, 可被计算机控制部件)
		+ 标定数据源/参考数据源: 为AI人工智能的记忆容量/标定数据反馈, 提供支持;

	* 人工智能'主机厂/整机开发':
		除了要把人工智能'零配件供应商'的工作, 全给做了, 还要做:
		+ 行为策略(决策-选择)
		+ 算法层归纳(决策-方法)
		+ 参考数据源, 成功案例(记忆)
		+ 模糊思考(随机)
		+ 数据标定, 校正(反馈)
		...
		全部都要做
