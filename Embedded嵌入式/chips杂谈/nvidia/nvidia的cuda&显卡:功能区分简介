ps: 你需要详细阅读一下, intel 显卡选购 这篇文章, 
		里面讲述了一个比较重要的概念: 
			显卡核心的核心频率对显卡性能有着比较重要的影响, 
			核心频率太低, 有时候会被别人: 一个顶2-3 个核心.
			而且显卡核心频率过低, 会导致显卡响应过慢, 操作体验不好.
			这方面显卡也是和CPU 差不多的.

		更关键的是:
			显卡核心多的情况下, 显卡驱动的程序质量, 
			严重影响到显卡性能的发挥, 
			linux nvidia 显卡驱动太烂, 会有一定折损,
			这种折损体现在: 
				显卡cuda 没有完全利用, 
				有核心却空闲起来, 导致显卡硬配沦为摆设.



1.什么是nvidia cuda???
	首先你要明白, nvidia 显卡, 
	实际上是一个并行,超多核,低频的GPU计算模组 + 显示输出回路 = nvidia显卡.
	而cuda 就是指具备GPU 计算能力的单元, 
	一个cuda 单元 = 一个GPU 核心 = 一个ALU.
	A 卡5 个核心 = 一个ALU = 一个计算单元.
	(详细差别, 请查看: A卡_N卡对比)


	显卡的核心频率, 值得的就是cuda 的运行主频, 
	例如gt240 的运行主频就是550MHz, 
	gt240 有96 个cuda, 也就是有96 个550MHz 的核心, 可以做运算.

	nvidia cuda 并不是在运算主频上胜过intel, 
	intel 也有浮点计算指令集: MMX, SSE, AVX 等
	(这些指令集不只是增强浮点运算能力, 还有其它游戏, 视频压缩, http 转码等).
	anyway, nvidia 在主频上, 比不上intel cpu, 也就是速度上是没有优势的.
	但是在数量上, nvidia 小小一个gpu 都有96 个运算单元, 
	这种规模是intel 没办法做到的.
	nvidia cuda 适合做慢速, 简单的运算, 
	可以分担一些慢速, 浮点, 傻瓜式的计算任务.


	nvidia cuda 核心之间, 是并行计算的. 
	由于核心太多, 管理起来很麻烦, 
	所以nvidia cuda 核心之间基本是不通信的.
	各自完成各自的计算任务, 然后直接返回结果.
	其实最主要的是: 
		程序员没办法均匀地利用这么多核心, 
		如果单独占用其中的一两个核心做运算.
		那nvidia cuda 的核心就是抢占的, 
		抢到核心就可以用到结束, 这跟intel 很不一样.
		(nvidia cuda 应该也支持'并发同步', 只是比较单调)
		[intel 是时间片 + 抢占 + 锁 + 调度于一体的集合, 
		 详情请看: CPU_kernel_时间片_抢占_锁_调度]

	由此看出, 虽然理论上, nvidia cuda 的计算能力比intel 强,
	但是实际上, 现在的程序还没有办法完全发挥nvidia 的所有计算能力.
	如果多核就有优势, 
	那么intel也可以做多个2.2Ghz的核心, 这类的E7 cpu, intel也有产.


总结:
	nvidia cuda 就是运算单元, 就是核心, 
	显卡的核心频率, 指的就是这些所有运算单元的频率.
	nvidia 一个cude = 一个ALU = 一个运算单元; 
	ATI 5-6 个核心 = 一个ALU = 一个运算单元.

	图片处理, 视频处理, 转码, 压缩解压解码等计算, 
	都是比较简单,傻瓜的计算, nvidia cuda 有优势.
	nvidia 适合重复, 大量操作,
	实际上浮点计算, 也只不过是计算步骤比较复杂而已, 
	nvidia 并不是算得快, 只不过是运算器多, 并发操作强, 所以算得快而已.

	算术逻辑运算单元[ ALU: Arithmetic Logic Unit ]





2.nvidia 显卡的性能分析:
例题: 有显卡为什么视频缓存会更快?
	*1.视频缓存:
		其实很简单, cuda 这么多核心, 
		已经将未来时间点的图像计算好了, 
		反正你一个视频, 就那么大, 拍好的视频也不会改变的, 
		这么说: 显存除了用来存储计算的临时数据, 还用来存储计算的结果.
		因为只有将未来点的数据存放好, 直接读取, 才算是: 视频缓存加速.

		这么想: 显存供应很紧张不是吗? 
		越是高清的视频, 解析度越高, 播放起来就越慢, 缓冲数据的长度就越短, 
		如果切断视频, 跳到后面播放, 就会卡一下
		(断点如果在缓存数据内, 还不算卡, 
		 如果不再缓存数据内, 就要重新开始做'视频缓冲')
		从头开始缓冲, 边缓冲边播放, 
		直到显卡计算能力超越了播放时间, 
		然后才会慢慢积累未来时间点的'视频缓存', 播放才会更顺畅.


	*2.像素解析度
		像素解析度 = 分辨率, 分辨率因屏幕大小不同, 需求也不一样.
		一般十七寸的屏幕, 最大也就1280*1024, 
		更大的显示器, 支持更大的解析度.
		显示器越大, 需要的分辨率也越高
		(不然没办法做到全屏, 你买这么大的显示器也没用).

		像素解析度过大, 会造成'数据码流'太大, 
		莫名其妙的增加显示输出设备的负担, 但是观看效果却没有很大的提升.
		肉眼分辨不出来的解析度, 再强调大, 也毫无意义.
		除非是电影院, 那种视频解析设备, 必然是很巨大的.


	*3.GPU运算:
		nvidia cuda 不做高速运算, 但是对于:
		图片处理, 视频处理, 转码, 压缩解压解码等计算, 
		比较简单,傻瓜的计算, 适合nvidia 重复, 大量操作.
		nvidia 都很擅长.

		但是由于管理这么多核心很麻烦, 
		nvidia 基本不让他们通信, 几乎每个核心都是单一通信, 
		每个核心都要占用'计算临时内存' + '计算结果存放内存', 
		这样对内存的依赖性, 就太大了.

		你会看到显卡的内存频率一般比核心主频要高很多, 
		还有很多增强版的'显卡专用内存', 一般都是业界最高速的内存.
		ddr3 时代, 显存ddr5 实际就是1866Mhz 的ddr3 终极版, 
		显存并不会摆脱时代的身影, ddr3 时代, 始终也是ddr3 显存.
		ddr5 只是口号而已, 宣传而已, 并不是真的ddr5

		所以显卡对显存的依赖性很强, 
		而且不同核心直接也不会加锁, 
		这么多核心, 程序员要怎样加锁?


		假如每个核心占用2mb 临时计算内存 + 4mb 的结果存放内存, 
		96*2*4都不是一个小数目;
		如果是显卡与系统共享内存, 呵呵, 
		不是显卡专用内存基本是废物, 共享内存还要通过PCI 传到显卡上面, 呵呵呵.
		显卡专用内存, 镶在显卡上面自己用, 
		而且不需要通过pci 通信, 再经过cpu 内存管理器, 存到cpu 内存上.
		这个传输过程, 实际比较消耗'主板总线', 实在是败笔.
		不要买有共享内存的显卡, 这只会证明了: 
		显卡核心太多, 显存太少喂不饱, 这种显卡一般造工很次. 
		宁愿买低端一点的真实内存显卡.


		核心数量和显存, 两个显卡的重要参数, 再有就是'显存带宽'.
		显存多, 核心多, '显存带宽'也不能窄, 
		显存的带宽一般都很大(64bit/128bit/256bit)
		不过这个没意思, '显存带宽'实际就是根据需求调节的, 
		并不是设计的重点, 但是可以是衡量显卡'数据吞吐量'的标准.
		'显存带宽'是nvidia cuda 显卡的计算能力指标, 
		但是实际cuda 发挥不发挥得出来, 还得看显存充足不充足.
		否则就是瞎扯.


	*4.实验:
		Nvidia 驱动完全安装之后机器性能比较好, 
		但是显示输出还是60fps, 之前不完全安装的时候显示输出也是60fps
		Nvidia Cuda 真的分担了很多浮点运算, 
		nvidia 显卡 = cuda + 显示输出电路. 是一种复杂的协处理器.








3.nvidia cuda 框架介绍:
	是一种针对支持CUDA功能的GPU(图形处理器)的C语言开发环境, 
	CUDA开发环境包括:
	· nvcc C语言编译器
	· 适用于GPU(图形处理器)的CUDA FFT和BLAS库
	· 分析器
	· 适用于GPU(图形处理器)的gdb调试器(在2008年3月推出alpha版)
	· CUDA运行时(CUDA runtime)驱动程序
		(目前在标准的NVIDIA GPU驱动中也提供)


	CUDA编程手册
	CUDA开发者软件开发包(SDK)提供了一些范例(附有源代码), 
	以帮助使用者开始CUDA编程. 
	这些范例包括:
	· 并行双调排序
	· 矩阵乘法
	· 矩阵转置
	· 利用计时器进行性能评价
	· 并行大数组的前缀和(扫描)
	· 图像卷积
	· 使用Haar小波的一维DWT
	· OpenGL和Direct3D图形互操作示例
	· CUDA BLAS和FFT库的使用示例
	· CPU-GPU C—和C++—代码集成
	· 二项式期权定价模型
	· Black-Scholes期权定价模型
	· Monte-Carlo期权定价模型
	· 并行Mersenne Twister(随机数生成)
	· 并行直方图
	· 图像去噪
	· Sobel边缘检测滤波器
	· MathWorks MATLAB&reg;
	新的基于1.1版CUDA的SDK 范例现在也已经发布了;



