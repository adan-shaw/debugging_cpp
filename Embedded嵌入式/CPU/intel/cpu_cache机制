< cpu cache 机制>



1.cpu cache 无法被干预:
	cpu 的cache 机制, 与用户程序!! 内核程序!! 没有必然的关系.
	cpu level 1,2,3 只是为了提高cpu 读取数据的命中率而已, 不提供写操作(不提供数据'存储服务')
	cpu level 1,2,3 内存修改是命中算法决定的, 无论是驱动程序员, 还是用户程序, 都不能进行细节化的干预, 唯一能做的是: 
		把具体某个线程绑定在一个固定的cpu 内核中, 让这个线程/进程只在某个固定的cpu 内核中运行, 提高命中率;



2.cpu cache 的架构, 性能:
	cpu 的缓存机制, 是基于线程栈进行映射实现的, 与进程堆无关!!
	所以, cpu 的缓存机制, 唯一起作用的就是线程栈, 一般情况下, linux 默认的线程栈大小=8MB, windows 默认的线程栈大小=1MB;
	cpu 的缓存机制, 默认是:
		L1 每个核心专用32kb [只读]    - 1ns
		L2 每个核心专用256kb [只读]   - 10ns
		L3 所有核心共享3-N MB [只读]  - 50ns
		RAM 内存 所有核心共享 [读写]   - 200ns (1ms = 1000us = 1000000ns, 200ns = 0.0002 ms)

	进程堆的空间增长方向, 是: 低位向高位增长; 
	低位的空间顺序是: text -> 已初始化的全局变量/静态变量 -> 未初始化的全局变量/静态变量 -> 堆(new/delete 会有频繁变动) -> ...

	进程栈的空间增长方向, 是: 高位向低位增长; 
	高位的空间顺序是: args 命令行参数 -> 线程栈(一条线程一个栈, 线程结束会触发回收, 会有频繁变动) ... 



3.cpu cache 命中机制:
	缓存的工作原理是当CPU要读取一个数据时, 首先从缓存中查找, 如果找到就立即读取并送给CPU处理;
	如果没有找到, 就用相对慢的速度从内存中读取并送给CPU处理, 同时把这个数据所在的数据块调入缓存中, 
	可以使得以后对整块数据的读取都从缓存中进行, 不必再调用内存. 

	正是这样的读取机制使CPU读取缓存的命中率非常高(大多数CPU可达90%左右), 
	也就是说CPU下一次要读取的数据90%都在缓存中, 只有大约10%需要从内存读取. 
	这大大节省了CPU直接读取内存的时间, 也使CPU读取数据时基本无需等待. 
	总的来说, CPU读取数据的顺序是先缓存后内存. 



4.cpu 的其它高速总线:
	除了CPU上面的PCI总线和内存通道是北桥, 其他都是南桥的. 
	那怪你的南桥这么热, 多媒体,网络,usb,硬盘 都归南桥管的话,有够忙的. 
	内存频率提高了, 整体外设互交速度进一步提高, 就更忙了. 

	现在的趋势:
		由于cpu 极力吞并gpu,内存控制器,显示控制器,
		现在的cpu 基本都是all in one.一体化芯片.

	所以现在基本没有北桥了, 
	大部分非io 操作控制器, 大部分都被集成在cpu 中, 一体封装发售了.



题外话:
	.so 共链接库装载进内存, 与cpu cache 缓存机制, 两种机制毫无联系, 完全无任何关联;
	.so 共链接库装载进内存, 只是为了节省内存;
	cpu cache 缓存机制, 只是为了提高cpu 的数据读取效率;

	.so 共链接库的数据, 不会直接装载进cpu cache;



